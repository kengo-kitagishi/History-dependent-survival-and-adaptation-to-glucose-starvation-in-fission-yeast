\chapter{Experimental setup}

\section{Measurement methods for molecular crowding}
なんで他の密度測定方法ではなく、QPIを用いたのかまで書きたかったら、generalな測定方法を挙げていって、この方法が良かったみたいなことを書けばよくて、その際には
\cite{nguyen2022quantitative}
non invasive way of 



It has been found that, for most biological molecules, including proteins and nucleic acids, the values of γ are close to 0.19 mL/g (\href{https://www.sciencedirect.com/science/chapter/bookseries/pii/S1063582318300024\#bib244}{Theisen, Johann, Deacon, \& Harding, 2000}), and the linearity is maintained for a wide range of concentrations \cite{zangle2014live}
(\href{https://www.sciencedirect.com/science/chapter/bookseries/pii/S1063582318300024\#bib12}{Barer and Tkaczyk, 1954}, \href{https://www.sciencedirect.com/science/chapter/bookseries/pii/S1063582318300024\#bib278}{Zangle and Teitell, 2014}, \href{https://www.sciencedirect.com/science/chapter/bookseries/pii/S1063582318300024\#bib282}{Zhao et al., 2011}). Therefore, refractive index measurement is a rather direct approach to determination of concentration of molecules in cell.
\section{Principle of QPI}
Differences in refractive index between a cell and its environment are imprinted upon light as different delays to the phase of light oscillations. Because frequencies of visible light are very high (400–800 THz), its oscillations cannot be directly recorded by imaging sensors. To become detectable, phase delay must be converted into measurable intensity. This is done in standard phase contrast and differential interference contrast microscopes. Quantification of the phase is accomplished by a group of methods known as quantitative phase imaging (QPI)
QPI is based on transmitted illumination that crosses a refractive sample (Fig. 1). When the cell's refractive index varies both across the sample and in depth, the relative phase accrued by light passing through the cell at horizontal position x is
\begin{equation}
    \Delta \phi(x)= \frac{2\pi}{\lambda} \int_0^{h(x)}[n_{cell}(x,z) - n_0]dz
\end{equation}
where z denotes depth within the sample, h(x) is the cell thickness profile, ncell is the cell's refractive index (which may vary depending on the position), n0 is a constant refractive index of the medium, and λ is the wavelength of light. Scattering is assumed insignificant in this model. 
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{}
    \caption{A diagram showing accumulation of phase delay of light passing through a cell}
    \label{fig:placeholder}
\end{figure}
\subsection{Common-path Methods}
common path QPI methods implement a considerably more compact interferometer after the sample. In this geometry, the two interfering light beams propagate through many of the same optical components, increasing robustness to vibrations and misalignments of the system as well as generally reducing the system's footprint. Because they can be placed after the sample, common-path systems can also be easily implemented at the output port of a microscope.
だから長期のタイムラプスに最適。

\subsection{Light propagation and angular spectrum method}
The propagation of monochromatic light in a homogeneous medium is governed by the Helmholtz equation:
\begin{equation}
\nabla^2 U(\mathbf{r}) + k^2 U(\mathbf{r}) = 0,
\end{equation}
where $k = 2\pi n/\lambda$ is the wavenumber, $n$ is the refractive index, $\lambda$ is the wavelength, and $\nabla^2 = \partial^2/\partial x^2 + \partial^2/\partial y^2 + \partial^2/\partial z^2$ is the Laplacian operator. The solution can be expressed as a superposition of plane waves with different spatial frequencies $(f_x, f_y)$:
\begin{equation}
U(x,y,z) = \int\int \tilde{U}(f_x, f_y, z) e^{2\pi i(f_x x + f_y y)} df_x df_y,
\end{equation}
where $\tilde{U}(f_x, f_y, z)$ is the angular spectrum. Substituting this into the Helmholtz equation yields the dispersion relation:
\begin{equation}
k_x^2 + k_y^2 + k_z^2 = k^2,
\end{equation}
where $k_x = 2\pi f_x$, $k_y = 2\pi f_y$, and
\begin{equation}
k_z = \sqrt{k^2 - k_x^2 - k_y^2} = \sqrt{k^2 - (2\pi f_x)^2 - (2\pi f_y)^2}
\end{equation}
is the z-component of the wavevector.

For propagation from $z=0$ to $z=d$, each plane wave component acquires a phase factor $e^{i k_z d}$:
\begin{equation}
\tilde{U}(f_x, f_y, d) = \tilde{U}(f_x, f_y, 0) \cdot e^{i k_z d}.
\end{equation}
The field at distance $d$ is then obtained by inverse Fourier transformation:
\begin{equation}
U(x,y,d) = \mathcal{F}^{-1}\left\{\tilde{U}(f_x, f_y, 0) \cdot e^{i k_z d}\right\}.
\end{equation}

\subsection{Band-pass limitation by the objective lens}

An objective lens with numerical aperture NA acts as a spatial frequency filter, passing only components with $\sqrt{f_x^2 + f_y^2} \leq \mathrm{NA}/\lambda$. The transmitted field spectrum is
\begin{equation}
\tilde{U}_{\mathrm{transmitted}}(f_x, f_y) = \tilde{U}_0(f_x, f_y) \cdot P(f_x, f_y),
\end{equation}
where $P(f_x, f_y)$ is the pupil function:
\begin{equation}
P(f_x, f_y) = \begin{cases}
1 & \text{if } \sqrt{f_x^2 + f_y^2} \leq f_{\mathrm{cutoff}} = \mathrm{NA}/\lambda \\
0 & \text{otherwise}
\end{cases}.
\end{equation}
This band-pass limitation determines the spatial resolution through the Abbe diffraction limit:
\begin{equation}
\Delta x_{\mathrm{Abbe}} = \frac{\lambda}{\mathrm{NA}}
\end{equation}
for coherent illumination.

subsection{Light propagation in 4f optical systems}

A 4f optical system consists of two lenses with focal length $f$ arranged such that the object plane, Fourier plane, and image plane are separated by distances $f$ as shown in Fig.~\ref{fig:4f_system}. This configuration performs spatial Fourier transformation and imaging, and is widely used in spatial light modulation, optical filtering, and holographic imaging systems.

\subsection{Light propagation in 4f optical systems}

A 4f optical system consists of two lenses with focal length $f$ arranged such that the object plane, Fourier plane, and image plane are separated by distances $f$. This configuration performs spatial Fourier transformation and imaging, and is widely used in spatial light modulation, optical filtering, and holographic imaging systems \cite{goodman2005}.

\subsubsection{System configuration}

The 4f system comprises the following elements (Fig.~\ref{fig:4f_system}):
\begin{itemize}
\item Object plane at $z = 0$
\item First lens (L1) with focal length $f$ at $z = f$
\item Fourier plane at $z = 2f$
\item Second lens (L2) with focal length $f$ at $z = 3f$
\item Image plane at $z = 4f$
\end{itemize}

\subsubsection{Fourier transformation by a single lens}

When an object is placed at the front focal plane of a lens with focal length $f$, the field at the back focal plane (Fourier plane) is proportional to the spatial Fourier transform of the object field \cite{goodman2005}:
\begin{equation}
U_F(x_F, y_F) = \frac{e^{ikf}}{i\lambda f} e^{i\frac{k}{2f}(x_F^2 + y_F^2)} \mathcal{F}\{U_0(x_0, y_0)\}\bigg|_{f_x = \frac{x_F}{\lambda f}, f_y = \frac{y_F}{\lambda f}}
\end{equation}
where $U_0$ is the object field, and the quadratic phase factor $\exp[ik(x_F^2 + y_F^2)/(2f)]$ represents the spherical wavefront curvature at the Fourier plane.

The spatial frequency components $(f_x, f_y)$ are mapped to coordinates in the Fourier plane according to:
\begin{equation}
f_x = \frac{x_F}{\lambda f}, \quad f_y = \frac{y_F}{\lambda f}
\end{equation}

\subsubsection{Spatial filtering in the 4f system}

A spatial filter (e.g., pinhole, amplitude mask) placed at the Fourier plane modifies the spatial frequency spectrum. The filter function $P(x_F, y_F)$ multiplies the Fourier-domain field:
\begin{equation}
U_F^+(x_F, y_F) = U_F(x_F, y_F) \cdot P(x_F, y_F)
\end{equation}

The second lens performs an inverse Fourier transformation, yielding the filtered image at $z = 4f$. For a symmetric 4f system without filtering ($P = 1$), the output is an inverted image of the input:
\begin{equation}
U_i(x_i, y_i) = -U_0(-x_i, -y_i) \cdot e^{i4kf}
\end{equation}
where the negative sign indicates spatial inversion in both transverse directions.

\subsection{Phase recovery through interferometry}

Since image sensors can only measure intensity $I = |U|^2$, the phase information $\phi$ in the complex field $U = A e^{i\phi}$ is lost upon detection. To recover the phase, we interfere the object field $U_s = A_s e^{i\phi_s}$ with a known reference field $U_r = A_r e^{i\phi_r}$. The detected intensity is
\begin{equation}
I = |U_s + U_r|^2 = |U_s|^2 + |U_r|^2 + U_s \cdot U_r^* + U_s^* \cdot U_r,
\end{equation}
which can be expanded as
\begin{equation}
I = A_s^2 + A_r^2 + 2A_s A_r \cos(\phi_s - \phi_r).
\end{equation}
The phase difference $\phi_s - \phi_r$ modulates the intensity as interference fringes. However, in an on-axis configuration, all four terms in Eq. (3.10) occupy the same region in Fourier space, preventing isolation of the phase-containing term $U_s \cdot U_r^*$.

\subsection{Off-axis configuration}

To separate the interferometric components in Fourier space, we introduce a carrier frequency by giving the object field an off-axis wavevector $(k_m^{\mathrm{off-axis}}, k_n^{\mathrm{off-axis}})$, where $(m, n)$ denote discrete pixel indices. In our common-path system, the reference field is spatially filtered by a pinhole at the Fourier plane to produce a quasi-plane wave:
\begin{equation}
U_r = A_r,
\end{equation}
while the object field carries the off-axis wavevector introduced by the Ronchi ruling grating:
\begin{equation}
U_s = A_s e^{i\phi_s} e^{i(k_m^{\mathrm{off-axis}} m + k_n^{\mathrm{off-axis}} n)}.
\end{equation}
The interference pattern then becomes
\begin{equation}
I_{m,n} = |U_s|^2 + |U_r|^2 + U_s \cdot U_r^* + U_s^* \cdot U_r = A_s^2 + A_r^2 + 2A_r A_s \cos[\phi_s + k_m^{\mathrm{off-axis}} m + k_n^{\mathrm{off-axis}} n].
\end{equation}

Taking the 2D Fourier transform with reciprocal coordinates $(p,q)$, we obtain
\begin{equation}
\tilde{I}(p,q) = \tilde{I}_{\mathrm{DC}}(p,q) + \mathcal{F}\{U_s \cdot U_r^*\}(p - k_m^{\mathrm{off-axis}}, q - k_n^{\mathrm{off-axis}}) + \mathcal{F}\{U_s^* \cdot U_r\}(p + k_m^{\mathrm{off-axis}}, q + k_n^{\mathrm{off-axis}}).
\end{equation}
The three components are now spatially separated in Fourier space. By selecting the +1st-order sideband and applying inverse Fourier transformation, the complex field $U_s$ is isolated and its phase $\phi_s = \arg(U_s)$ is extracted.

\subsection{Off-axis hologram formation}

In off-axis DH, the interference patterns between the object field and reference field are captured with an image sensor. Assuming $z = 0$ as the sample location, the object field at the sensor is
\begin{equation}
E'_{m,n} = \frac{1}{M^2} E_0 \exp[i\phi_{m,n}] \exp[i(k_m^{\mathrm{off-axis}} m + k_n^{\mathrm{off-axis}} n)],
\end{equation}
where $M$ is the magnification, $E_0$ is the incident field amplitude, $(k_m^{\mathrm{off-axis}}, k_n^{\mathrm{off-axis}})$ is the off-axis carrier frequency introduced by the Ronchi ruling grating, and $\phi_{m,n}$ contains the optical phase delay induced by the sample. The reference field is
\begin{equation}
R_{m,n} = R_0,
\end{equation}
which is approximately constant across the field of view after spatial filtering by the pinhole at the Fourier plane.

The recorded hologram intensity at pixel $(m,n)$ is
\begin{equation}
I_{m,n}^{\mathrm{DH}} = \left|E'_{m,n} + R_{m,n}\right|^2 = |E'_{m,n}|^2 + |R_{m,n}|^2 + E'_{m,n} \cdot R_{m,n}^* + \mathrm{c.c.}
\end{equation}
This can be separated into interferometric terms ($J_{m,n}^{\mathrm{int}} e^{i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)}$ and its complex conjugate) and noninterferometric term ($J_{m,n}^{\mathrm{non-int}}$) as
\begin{equation}
I_{m,n}^{\mathrm{DH}} = J_{m,n}^{\mathrm{non-int}} + J_{m,n}^{\mathrm{int}} e^{i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)} + (J_{m,n}^{\mathrm{int}})^* e^{-i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)},
\end{equation}
where $J_{m,n}^{\mathrm{non-int}} = |E'_{m,n}|^2 + |R_{m,n}|^2$ and $J_{m,n}^{\mathrm{int}} = E'_{m,n} \cdot R_{m,n}^*$.

\section{Reconstruction procedure}

The image-reconstruction procedure comprises (1) 2D discrete FT, (2) sideband centering, (3) low-pass (LP) filtering, and (4) 2D discrete inverse FT (IFT), followed by background subtraction. The 2D FT of the hologram is written as
\begin{equation}
i_{p,q}^{\mathrm{DH}} = j_{p,q}^{\mathrm{non-int}} + j_{p-k_m^{\mathrm{off-axis}}, q-k_n^{\mathrm{off-axis}}}^{\mathrm{int}} + j_{p+k_m^{\mathrm{off-axis}}, q+k_n^{\mathrm{off-axis}}}^{\mathrm{int}*},
\end{equation}
where $(p,q)$ is the reciprocal coordinate of $(m,n)$. The three components are spatially separated in the Fourier space due to the off-axis wavevector.

The interferometric term is extracted by first identifying the +1st-order sideband peak position $(p_{\mathrm{off}}, q_{\mathrm{off}})$ and then shifting the spatial frequency to center the sideband:
\begin{equation}
I_{m,n}^{(c)} = I_{m,n}^{\mathrm{DH}} \cdot e^{-i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)}.
\end{equation}
A circular LP filter $H_{p,q}$ with radius
\begin{equation}
r_{\mathrm{aperture}} = \frac{2\pi \mathrm{NA}}{\lambda} \cdot N \cdot \Delta p
\end{equation}
is applied in the Fourier domain, where $N$ is the hologram size and $\Delta p$ is the pixel pitch at the object plane. This corresponds to the spatial frequency cutoff determined by the NA of the objective lens. After LP filtering, 2D discrete IFT is performed to obtain the phase:
\begin{equation}
\phi_{m,n}^{\mathrm{Meas}} = \arg[\mathrm{LP}(I_{m,n}^{(c)})].
\end{equation}

The OPD is obtained after removing the complex amplitude distribution of the illumination light without the sample (background):
\begin{equation}
\phi_{m,n} = \arg\left[\frac{\mathrm{LP}(I_{m,n}^{\mathrm{sample}} \cdot e^{-i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)})}{\mathrm{LP}(I_{m,n}^{\mathrm{bg}} \cdot e^{-i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)})}\right].
\end{equation}
The final OPD image is obtained by subtracting the mean value of the background region to remove the offset. The conversion from phase to OPD is performed as
\begin{equation}
\mathrm{OPD}(x,y) = \frac{\phi(x,y) \lambda}{2\pi}.
\end{equation}
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{}
    \caption{Reconstruction procedure of off-axis DH}
    \label{fig:placeholder}
\end{figure}

\subsection{Spatial resolution and Fourier domain parameters}

The spatial resolution in off-axis DH is determined by the NA of the objective lens and the discrete sampling in the Fourier domain. For coherent illumination, the spatial frequency cutoff imposed by the NA is
\begin{equation}
f_{\mathrm{cutoff}} = \frac{\mathrm{NA}}{\lambda},
\end{equation}
which corresponds to the Abbe diffraction limit given in Eq. (3.9).

The aperture diameter in pixels is determined by the field of view (FOV) and the spatial frequency cutoff. For a hologram with $N \times N$ pixels and object-plane pixel pitch $\Delta p$, the FOV is $\mathrm{FOV} = N \cdot \Delta p$. The aperture diameter in pixels is
\begin{equation}
D_{\mathrm{ap}} = 2 \left\lfloor \frac{\mathrm{NA}}{\lambda} \cdot \mathrm{FOV} \right\rfloor + 1,
\end{equation}
where $\lfloor \cdot \rfloor$ denotes the floor function. This aperture size $D_{\mathrm{ap}}$ directly determines the size of the reconstructed OPD image. The reconstructed pixel size is
\begin{equation}
\Delta p_{\mathrm{recon}} = \frac{\mathrm{FOV}}{D_{\mathrm{ap}}} \approx \frac{\lambda}{2\mathrm{NA}}.
\end{equation}

Two stages of sampling must be considered in the system design. First, the raw hologram must satisfy the Nyquist sampling criterion to avoid aliasing:
\begin{equation}
\Delta p < \frac{\lambda}{2 \cdot \mathrm{NA}}.
\end{equation}
An oversampling factor of 2--4$\times$ is typical for robust hologram acquisition. Second, after Fourier filtering, the reconstructed OPD image pixel size is designed to match the Nyquist requirement, where one resolution element ($\lambda/\mathrm{NA}$) spans approximately two pixels.

For our system with $\lambda = 658$ nm, NA = 0.95, 40$\times$ magnification, and camera pixel size of 3.45 μm, the key parameters are calculated as follows. The object-plane pixel pitch is $\Delta p = 3.45~\mu\mathrm{m}/40 = 86.25$ nm, yielding a FOV of $2048 \times 86.25$ nm = 176.6 μm. The Abbe limit for coherent illumination is $\Delta x_{\mathrm{Abbe}} = 658/0.95 = 692$ nm, and the Nyquist requirement is $\Delta p_{\mathrm{Nyquist}} = 658/(2 \times 0.95) = 346$ nm. The raw hologram sampling achieves an oversampling factor of $346/86.25 = 4.0\times$, ensuring aliasing-free acquisition. The aperture diameter is
\begin{equation}
D_{\mathrm{ap}} = 2\left\lfloor \frac{0.95}{658 \times 10^{-9}} \times 176.6 \times 10^{-6} \right\rfloor + 1 = 507~\mathrm{pixels},
\end{equation}
and the reconstructed pixel size is $\Delta p_{\mathrm{recon}} = 176.6~\mu\mathrm{m}/507 = 348$ nm, which closely matches the Nyquist requirement.
\section{Optical system of QPI}

The optical system of QPI is described in Fig. ??. The light source consisted of a 658 nm, 20 mW single-mode fiber-pigtailed laser diode (LP660-SF20, Thorlabs) mounted in an LDM9LP mount. The laser was controlled by an LDC202C benchtop LD current controller (±200 mA) and a TED200C temperature controller (12 W, Thorlabs), connected via CAB400 and CAB420-15 cables, respectively. The output beam was collimated using an FC/PC fiber collimator (CFC2-B, $f$ = 2.0 mm, Thorlabs) to illuminate the sample. 
The optical field transmitted through the sample was magnified with a 40× objective lens (Nicon, NA = 0.95) and replicated with a Ronchi ruling grating (120 lines per mm, Edmund Optics \#66-342). We employ diffraction phase microscopy (i.e., common-path off-axis DH) as the QPM. The first-order diffraction light is used as the object light, while the zeroth-order diffraction light low-pass filtered with a 25 μm pinhole (P25K, Thorlabs) placed at the Fourier plane is converted to a quasi-plane wave that acts as the reference light. The interferogram between these states in the off-axis configuration is recorded with a monochrome USB 3.0 CMOS camera (acA2440-75, Basler ace, 2448 × 2048 pixels, pixel size of 3.45 μm, full-well capacity of $\sim$10 ke$^-$) after relay lenses (ACT508-200-A, $f$ = 200 mm, Ø2", Thorlabs) in a 4f configuration. The number of pixels in the raw hologram and reconstructed OPD image are 2048 × 2048 and 507 × 507, respectively. The pixel size of the OPD image is set to the diffraction limit of $\sim$350 nm, determined by the NA of the objective lens.
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{figure/QPI optical systems.pdf}
    \caption{Optical System ofQPI}
    \label{fig:placeholder}
\end{figure}
\section{Design of the optical system}

When designing an off-axis DH optical system, two conditions must be satisfied. First, the magnitude of the off-axis wavevector $k^{\mathrm{off-axis}} = \sqrt{(k_m^{\mathrm{off-axis}})^2 + (k_n^{\mathrm{off-axis}})^2}$ must be sufficiently large to avoid overlap of the interferometric and noninterferometric terms in the Fourier space. The radius of the interferometric component in the Fourier space is $2\pi \mathrm{NA}/(\lambda M)$, while that of the noninterferometric component is $2\pi \cdot 2\mathrm{NA}/(\lambda M)$, as the noninterferometric term is expressed by the autocorrelation of the frequency spectrum. Hence, $k^{\mathrm{off-axis}}$ must satisfy
\begin{equation}
k^{\mathrm{off-axis}} \geq 3 \left(\frac{2\pi \mathrm{NA}}{\lambda M}\right).
\end{equation}

Second, the spatial frequency of the interferometric component should not exceed 1/2 of the sensor's pitch (Nyquist criterion):
\begin{equation}
\frac{k^{\mathrm{off-axis}}}{\sqrt{2}} + \frac{2\pi \mathrm{NA}}{\lambda M} \leq \frac{2\pi f_{\mathrm{pitch}}}{2},
\end{equation}
where $f_{\mathrm{pitch}}$ is the inverse of the sensor's pixel pitch. Combining these two conditions yields
\begin{equation}
\frac{2\pi \cdot 3\mathrm{NA}}{\lambda M} \leq k^{\mathrm{off-axis}} \leq  \frac{2\pi f_{\mathrm{pitch}}}{\sqrt{2}}- \frac{2\sqrt{2}\pi\mathrm{NA}}{\lambda M}.
\end{equation}

When designing an off-axis DH optical system, two conditions must be satisfied. First, the magnitude of the off-axis wavevector $k^{\mathrm{off-axis}} = \sqrt{(k_m^{\mathrm{off-axis}})^2 + (k_n^{\mathrm{off-axis}})^2}$ must be sufficiently large to avoid overlap of the interferometric and noninterferometric terms in the Fourier space. The radius of the interferometric component in the Fourier space is $2\pi \mathrm{NA}/(\lambda M)$, while that of the noninterferometric component is $2\pi \cdot 2\mathrm{NA}/(\lambda M)$, as the noninterferometric term is expressed by the autocorrelation of the frequency spectrum. Hence, $k^{\mathrm{off-axis}}$ must satisfy
\begin{equation}
k^{\mathrm{off-axis}} \geq 3 \left(\frac{2\pi \mathrm{NA}}{\lambda M}\right).
\end{equation}

Second, the spatial frequency of the interferometric component should not exceed 1/2 of the sensor's pitch (Nyquist criterion). For a wavevector in an arbitrary direction, the worst case occurs along the diagonal direction, requiring:
\begin{equation}
\frac{k^{\mathrm{off-axis}}}{\sqrt{2}} + \frac{2\pi \mathrm{NA}}{\lambda M} \leq \frac{2\pi f_{\mathrm{pitch}}}{2},
\end{equation}
where $f_{\mathrm{pitch}}$ is the inverse of the sensor's pixel pitch. Combining these two conditions yields
\begin{equation}
\frac{2\pi \cdot 3\mathrm{NA}}{\lambda M} \leq k^{\mathrm{off-axis}} \leq \sqrt{2}\pi \left(f_{\mathrm{pitch}} - \frac{2\mathrm{NA}}{\lambda M}\right).
\end{equation}

For our system, the off-axis wavevector is determined by the grating (120 lines per mm) placed at the sample conjugate plane. At the sensor plane (image plane), the grating period is 8.33 μm, yielding an off-axis wavevector magnitude of
\begin{equation}
k^{\mathrm{off-axis}} = \frac{2\pi}{8.33~\mu\mathrm{m}} = 7.54 \times 10^5~\mathrm{rad/m}.
\end{equation}

We verify that our system satisfies both design conditions at the sensor plane. For the first condition (overlap avoidance):
\begin{equation}
k^{\mathrm{off-axis}} = 7.54 \times 10^5 \geq 3 \times \frac{2\pi \times 0.95}{658 \times 10^{-9} \times 40} = 6.80 \times 10^5~\mathrm{rad/m}.
\end{equation}
For the second condition (Nyquist criterion), with sensor pixel pitch of 3.45 μm giving $f_{\mathrm{pitch}} = 1/3.45~\mu\mathrm{m} = 2.90 \times 10^5~\mathrm{m}^{-1}$:
\begin{equation}
k^{\mathrm{off-axis}} = 7.54 \times 10^5 \leq \sqrt{2}\pi \left(2.90 \times 10^5 - \frac{2 \times 0.95}{658 \times 10^{-9} \times 40}\right) = 9.68 \times 10^5~\mathrm{rad/m}.
\end{equation}
Both conditions are satisfied, confirming that the optical system design is appropriate for aliasing-free hologram acquisition.

For our system with $\lambda = 658$ nm, NA = 0.95, 40$\times$ magnification, and camera pixel size of 3.45 μm, the key parameters are calculated as follows. The object-plane pixel pitch is $\Delta p = 3.45~\mu\mathrm{m}/40 = 86.25$ nm, yielding a FOV of $2048 \times 86.25$ nm = 176.6 μm. The Abbe limit for coherent illumination is $\Delta x_{\mathrm{Abbe}} = 658/0.95 = 692$ nm, and the Nyquist requirement is $\Delta p_{\mathrm{Nyquist}} = 658/(2 \times 0.95) = 346$ nm. The raw hologram sampling achieves an oversampling factor of $346/86.25 = 4.0\times$, ensuring aliasing-free acquisition. The aperture diameter is
\begin{equation}
D_{\mathrm{ap}} = 2\left\lfloor \frac{0.95}{658 \times 10^{-9}} \times 176.6 \times 10^{-6} \right\rfloor + 1 = 511~\mathrm{pixels},
\end{equation}
and the reconstructed pixel size is $\Delta p_{\mathrm{recon}} = 176.6~\mu\mathrm{m}/511 = 346$ nm, which closely matches the Nyquist requirement.

\subsection{Verification of the off-axis configuration}

To validate the optical system design, we compare the theoretically calculated off-axis wavevector with the experimentally measured carrier frequency in the Fourier domain. From the grating specifications, the theoretical off-axis wavevector at the sensor plane (image plane) is $k_{\mathrm{theory}}^{\mathrm{off-axis}} = 7.54 \times 10^5~\mathrm{rad/m}$ as calculated above.

Experimentally, the off-axis carrier frequency is determined from the position of the +1st-order sideband in the Fourier-transformed hologram. For our system, the measured sideband peak position is $(m_{\mathrm{off}}, n_{\mathrm{off}}) = (1623, 1621)$ in the 2048 × 2048 pixel raw hologram, where the DC component is centered at $(1024, 1024)$. The offset from the center is
\begin{equation}
\Delta m = 1623 - 1024 = 599~\mathrm{pixels}, \quad \Delta n = 1621 - 1024 = 597~\mathrm{pixels}.
\end{equation}

The magnitude of the off-axis wavevector in pixel units is
\begin{equation}
k_{\mathrm{pixel}}^{\mathrm{off-axis}} = \sqrt{(\Delta m)^2 + (\Delta n)^2} = \sqrt{599^2 + 597^2} = 845.8~\mathrm{pixels}.
\end{equation}

To convert this to physical units at the sensor plane, we use the spatial frequency resolution determined by the sensor FOV:
\begin{equation}
\Delta f_{\mathrm{sensor}} = \frac{1}{\mathrm{FOV}_{\mathrm{sensor}}} = \frac{1}{2048 \times 3.45~\mu\mathrm{m}} = \frac{1}{7.07~\mathrm{mm}} = 141.5~\mathrm{m}^{-1}.
\end{equation}

The spatial frequency of the carrier at the sensor plane is
\begin{equation}
f_{\mathrm{exp}}^{\mathrm{off-axis}} = 845.8 \times 141.5 = 1.20 \times 10^5~\mathrm{cycles/m},
\end{equation}
corresponding to a wavevector of
\begin{equation}
k_{\mathrm{exp}}^{\mathrm{off-axis}} = 2\pi f_{\mathrm{exp}}^{\mathrm{off-axis}} = 2\pi \times 1.20 \times 10^5 = 7.53 \times 10^5~\mathrm{rad/m}.
\end{equation}

This excellent agreement confirms that the grating-based off-axis configuration is correctly implemented and that the optical system operates as designed.


\section{Phase sensitivity}

To discuss the OPD precision of off-axis DH, determined by the temporal OPD noise, we first add the noise term $z_{m,n}^{\mathrm{DH}}$ to Eq. (3.18), such that
\begin{equation}
I_{m,n}^{'\mathrm{DH}} = J_{m,n}^{\mathrm{non-int}} + J_{m,n}^{\mathrm{int}} e^{-i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)} + (J_{m,n}^{\mathrm{int}})^* e^{i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)} + z_{m,n}^{\mathrm{DH}}.
\end{equation}
The OPD image containing noise is represented by
\begin{align}
\phi'_{m,n} &= \arg\left[\mathrm{LP}\left(\frac{I_{m,n}^{'\mathrm{DH}} e^{i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)}}{|J_{m,n}^{\mathrm{int}}|}\right)\right] \nonumber \\
&= \arg\left[e^{i\phi_{m,n}}\left(1 + \frac{\mathrm{LP}(z_{m,n}^{\mathrm{DH}} e^{i(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n)})}{|J_{m,n}^{\mathrm{int}}| e^{i\phi_{m,n}}}\right)\right] \nonumber \\
&= \phi_{m,n} + \frac{z_{m,n}^{\mathrm{DH}} \sin(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n - \phi_{m,n}) \ast H_{m,n}}{|J_{m,n}^{\mathrm{int}}|},
\end{align}
where $H_{m,n}$ denotes the IFT of the pupil function $h_{k,l}$ for LP filtering, and $\ast$ represents convolution. The temporal OPD standard deviation at each spatial pixel $\sigma_{\phi'}^{\mathrm{DH}}$ can be obtained by calculating the square root of the variance of $\phi'_{m,n}$ as
\begin{align}
\sigma_{\phi'}^{\mathrm{DH}} &= \sqrt{\mathrm{Var}(\phi'_{m,n})} = \frac{1}{|J_{m,n}^{\mathrm{int}}|} \sqrt{[\mathrm{Var}(z_{m,n}^{\mathrm{DH}}) \sin^2(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n - \phi_{m,n})] \ast H_{m,n}^2} \nonumber \\
&= \frac{1}{|J_{m,n}^{\mathrm{int}}|} \sqrt{\left[\mathrm{Var}(z_{m,n}^{\mathrm{DH}}) \frac{1 - \cos 2(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n - \phi_{m,n})}{2}\right] \ast H_{m,n}^2}.
\end{align}

In the case of optical shot-noise-limited detection, $\mathrm{Var}(z_{m,n}^{\mathrm{DH,shot}})$ is given by
\begin{equation}
\mathrm{Var}(z_{m,n}^{\mathrm{DH,shot}}) = \mathrm{Mean}(I_{m,n}^{\mathrm{DH}}) = J_{m,n}^{\mathrm{non-int}} + 2|J_{m,n}^{\mathrm{int}}| \cos(\phi_{m,n} - k_m^{\mathrm{off-axis}}m - k_n^{\mathrm{off-axis}}n).
\end{equation}
All terms outside the LP bandwidth, such as $\cos 2(k_m^{\mathrm{off-axis}}m + k_n^{\mathrm{off-axis}}n - \phi_{m,n})$ in Eq. (3.43) and $\cos(\phi_{m,n} - k_m^{\mathrm{off-axis}}m - k_n^{\mathrm{off-axis}}n)$ in Eq. (3.44), are removed by the LP-filtering operation $\ast H_{m,n}$. Because $h_{k,l}$ is unity within its passband and zero elsewhere, $H_{m,n}^2$ can be approximated by the delta function $\delta_{m,n}$, and the summation of its amplitude over the entire pixel range is expressed as
\begin{equation}
\sum_{m,n} H_{m,n}^2 = \sum_{k,l} h_{k,l}^2 \cdot \frac{A_{\mathrm{aperture}}}{A_{\mathrm{sensor}}},
\end{equation}
where $A_{\mathrm{sensor}}$ is the total number of sensor pixels and $A_{\mathrm{aperture}}$ is the number of pixels inside the LP bandwidth. By substituting Eq. (3.45) into Eq. (3.43), we obtain the optical shot-noise-limited OPD precision as
\begin{equation}
\sigma_{\phi'}^{\mathrm{DH,shot}} = \frac{\sqrt{|J_{m,n}^{\mathrm{non-int}}| \ast H_{m,n}^2}}{\sqrt{2}|J_{m,n}^{\mathrm{int}}|} = \sqrt{\frac{|J_{m,n}^{\mathrm{non-int}}|}{2|J_{m,n}^{\mathrm{int}}|^2}} \sqrt{\frac{A_{\mathrm{aperture}}}{A_{\mathrm{sensor}}}}.
\end{equation}

Equation (3.46) can be extended to obtain the OPD precision including both the optical shot noise and the sensor's read-out noise as
\begin{equation}
\sigma_{\phi'}^{\mathrm{DH,shot+sensor}} = \sqrt{\frac{|J_{m,n}^{\mathrm{non-int}}| + \mathrm{Var}(z_{m,n}^{\mathrm{sensor}})}{2|J_{m,n}^{\mathrm{int}}|^2}} \sqrt{\frac{A_{\mathrm{aperture}}}{A_{\mathrm{sensor}}}},
\end{equation}
where $\mathrm{Var}(z_{m,n}^{\mathrm{sensor}})$ is the variance of the sensor read-out noise.

Using the visibility $V = 2|J_{m,n}^{\mathrm{int}}|/J_{m,n}^{\mathrm{non-int}}$ and noting that $J_{m,n}^{\mathrm{non-int}} = A_s^2 + A_r^2$ is the mean intensity (in units of electrons), the shot-noise-limited phase sensitivity can be written as
\begin{equation}
\sigma_{\phi}^{\mathrm{shot}} = \frac{1}{V} \sqrt{\frac{2}{J_{m,n}^{\mathrm{non-int}}}} \sqrt{\frac{A_{\mathrm{aperture}}}{A_{\mathrm{sensor}}}} = \frac{1}{V\sqrt{N_e}} \sqrt{\frac{2A_{\mathrm{aperture}}}{A_{\mathrm{sensor}}}},
\end{equation}
where $N_e = J_{m,n}^{\mathrm{non-int}}$ is the total number of electrons.

In common-path off-axis holography with background subtraction, the noise propagates from both sample and background measurements. Since the measurements are independent, the variance becomes $\mathrm{Var}[\Delta I] = 2\sigma_I^2$, yielding
\begin{equation}
\sigma_{\phi}^{\mathrm{bg\ sub}} = \sqrt{2} \times \sigma_{\phi}^{\mathrm{shot}} = \frac{\sqrt{2}}{V\sqrt{N_e}} \sqrt{\frac{2A_{\mathrm{aperture}}}{A_{\mathrm{sensor}}}} = \frac{2}{V\sqrt{N_e}} \sqrt{\frac{A_{\mathrm{aperture}}}{A_{\mathrm{sensor}}}}.
\end{equation}

The phase sensitivity exhibits a quadratic dependence on visibility ($\sigma_{\phi} \propto V^{-1}$) and a square-root dependence on the number of electrons ($\sigma_{\phi} \propto N_e^{-1/2}$), making visibility optimization critical for achieving high sensitivity.


\newpage
\section{Microscope and imaging setup}
Microscopy was conducted on an inverted Nikon Ti microscope (Nikon Instruments Inc.) fitted with a 40×/0.95 NA air objective. Samples were maintained at 30 °C with a stage-top incubator (Tokai Hit model ). The microscope hardware including motorized stage, shutters, Perfect Focus System (PFS) autofocus and image acquisition were controlled using Micro-Manager (v) open-source software.
\section{Biological replicates}
S.pombe were streakrd from frozen stock on an YE plate and grown for 24 hours at 30℃. Single colonies were then picked and grown in 10 ml of EMM at 30℃ with shaking for 24 hours.

\section{Image analysis to retrieve phase shifts}
To reduce post-processing time, each z-stack was cropped to a square region containing the cell(s) of interest and a border of at least 40 pixels, and the focal plane was identified. This cropping was accomplished first using FIJI v. 1.53c to identify regions of interest (ROIs) within a thresholded standard deviation z-projection image of each brightfield z-stack. Using custom Matlab R2019a (Mathworks) scripts, images were cropped to the ROIs and the standard deviation of the pixels in each ROI was computed. The focal plane was defined based on the image in the stack with the lowest standard deviation. Three images above and three images below the focal plane separated by 500 nm were used to quantify cytoplasmic density. Based on these images, the phase information was calculated using a custom Matlab script implementing a previously published algorithm (Bostan et al., 2016). In brief, this method relates the phase information of the cell to bright-field image intensity changes along the z-direction. Equidistant, out-of-focus images above and below the focal plane are used to estimate intensity changes at various defocus distances. A phase-shift map is reconstructed in a non-linear, iterative fashion to solve the transport-of-intensity equation.[from variational]

\section{Image Preprocessing}
Using Matlab, images were background-corrected by fitting a Gaussian to the highest peak of the histogram (corresponding to the background pixels) of the phase-shift map and shifting every pixel so that the background intensity peak corresponded to zero phase shift. These background-corrected phase-shift maps were converted into binary images using watershedding for cell segmentation; where necessary, binary images were corrected manually to ensure accurate segmentation. Binary images were segmented using Morphometrics (Ursell et al., 2017) to generate subpixel-resolved cell outlines.

Each cell outline was skeletonized using custom Matlab code as follows. First, the closest-fitting rectangle around each cell was used to define the long axis of the cell. Perpendicular to the long axis, sectioning lines at 250 nm intervals and their intersection with the cell contour were computed. The centerline was then updated to run through the midpoint of each sectioning line between the two contour-intersection points. The slope of each sectioning line was updated to be perpendicular to the slope of the centerline around the midpoint. Sectioning lines that crossed a neighboring line were removed. Cell volume and surface area were calculated by summing the volume or area of each section, assuming rotational symmetry. Volume and area of the poles were calculated assuming a regular spherical cap.

To convert the mean intensity of the phase-shift within each cell into absolute concentration (in units of mg/mL), the mean of all cells across all time points was first calculated. Then, the decrease in phase shift induced by a prescribed concentration of BSA (typically 100 mg/mL) was defined as the difference between the mean of the phase shifts before and after the BSA imaging time point and the phase shift during the BSA time point. This difference in intensity established the calibration scaling between phase shift intensity and the concentration of BSA (Figure 1B). The cytoplasmic density of each cell was then calculated by dividing the mean phase shift of the cell by the aforementioned scaling factor. The mass of each cell was inferred from its mean density and volume.[from variational]

\section{Volume estimation}
戸田さんの哺乳類細胞の体積推定や他のrod shape近似の書き方を調べる

\section{一細胞観察のためのデバイス}
シングルセルレベルで発現状態の時間変化を長期的に取得するため,mother machineと呼ばれるPolydimethylsiloxane(PDMS)製マイクロ流体デバイスを用いて計測を行った.mother machineは,制御された増殖条件下で個々の細菌細胞を長期間にわたって観察・分析するために設計された特殊なマイクロ流体デバイスである\cite{wang2010robust}.2010年にWangらによって大腸菌の一細胞解析のために初めて開発されたこの装置は,単一細胞の動態,細菌の老化,遺伝子発現,およびその他のさまざまな細胞プロセスを,これまでにない時間的・空間的解像度で研究するための非常に貴重なツールとなっている.
この基本設計は,数百から数千の細長い増殖チャネルが,増殖培地が連続的に流れる大きな主溝に対して垂直に配置されている.各増殖チャネルは通常,細菌細胞の1列分が収まるだけの幅しかなく,一端が閉じられている.チャネルは,ソフトリソグラフィ技術を用いて,透明でガス透過性のポリマーであるポリジメチルシロキサン（PDMS）で製造される.その後,PDMSチップはガラスカバースリップに接着され,顕微鏡観察に適した透明度を維持しながら密閉された流路が形成される(図1).

\begin{figure}[htbp]
\centering
\includegraphics[width=100mm]{MM}
\caption{\textnormal{\textbf{マザーマシンの構造の概略図} 培地は矢印に沿って流れ,メイン流路に流れる.穴は中央チャネルの入口と出口に穴を開け,新鮮培地（入口）と廃液（出口）用のチューブを接続する.}}
\end{figure}

「マザー・マシン」という名称は,何百世代にもわたって同じ「母細胞」を追跡できる能力に由来する.細胞がこれらの流路で成長し分裂すると,各流路の行き止まりにある細胞はそのまま捕捉された状態が維持されるが,その娘細胞は徐々に主溝に向かって押し出され,最終的には主溝を勢いよく流れる培地によって洗い流される(図2).この閉じ込められた細胞は,その極の1つが常に流路の末端に接しており,世代から世代へと受け継がれるため,「母細胞」と呼ばれる.この設計により,定常状態の増殖条件を維持しながら,何百もの細胞分裂にわたって同じ母細胞を追跡することが可能になる.
主溝を流れる新鮮な培地の連続的な流れは,成長チャネルへの拡散により,すべての細胞に栄養素を一定に供給する.研究により,栄養素の拡散は数秒単位の時間スケールで起こり,一般的な栄養素の取り込み時間である数分よりもはるかに速いことが示されており,均一な栄養条件が確保されることが分かっている\cite{wang2010robust} \cite{taheri2015cell}.また,主溝を流れる培地により,成長チャネルから出てきた娘細胞が除去されることで過密状態が回避され,均一な成長条件が維持される.さらに,マザーマシンの重要な利点の一つは培地条件の切り替えが容易なことで,培養条件を素早く変化させることができるため,研究者は環境変化に対する細胞の反応を研究することができる.

\begin{figure}[htbp]
\centering
\includegraphics[width=100mm]{Mother_Machine}
\caption{\textnormal{\textbf{マザーマシンの観察チャネルの概略図} ”母細胞”は成長チャネルの端に捕捉されており, 中央のフローセルに垂直に並んだ成長チャネルは, 新鮮な培地を供給し, 娘細胞をかき出す.}}
\end{figure}

mother machineは細胞は固定された焦点面に留まり,高開口数対物レンズを使用して簡単に画像化できるため,この装置は蛍光顕微鏡にも適している.また,成長チャネル間の間隔は,チャネル間の蛍光の漏れを最小限に抑えつつ,同時に観察できる細胞の数を最大限に増やすように最適化することができる.典型的な実験では,一定の間隔（通常は数分ごと）で10～12の視野を撮影し,各視野には約100個の細胞が含まれる.その結果,長期間にわたって数千もの細胞系統を観察することができる.こうした利点を活かして,mother machineは老化\cite{wang2010robust}\cite{nakaoka2017aging},飢餓適応\cite{bakshi2021tracking},抗生物質耐性\cite{kaplan2021observation},細胞分化\cite{russell2017noise},細胞壁の成長メカニズム\cite{amir2014bending}など,さまざまな研究分野で活用されている.

本研究で使用したmother machineでは,幅180~$\mu$\text{m}の太い1本の流路に沿って垂直に,幅約6.3~$\mu$\text{m},長さ約40~$\mu$\text{m}の観察用チャンバーが多数配列している.流路の両端にはそれぞれシリンジと廃液に繋がるチューブが接続されており,シリンジポンプにより一定速度で送り出される培地が流路内を一方向に流れることでデバイス中の培養環境がおよそ定常に保たれる.導入された細胞はこのチャンバー内に入り込み,ほぼ一列に限定された状態で増殖するマザーマシンは,メインフロートレンチに沿って多数の流路が並ぶように設計されており,メインフロートレンチ内を流れる培地を変化させることで,細胞の環境条件を精密に制御することが可能である.

\section{Yeast Strain and Culture Conditions}
We used a Schizosaccharomyces pombe strain (HN0101; h\^- leu1-32::leu1\^+-Padh1-mNeonGreen) expressing mNeonGreen under the control of the constitutive adh1 promoter. The S. pombe adh1 promoter is widely recognized as a strong constitutive promoter and has been extensively used for gene expression systems and vector construction in fission yeast \cite{verma2014high, grimm1991strong, forsburg1993comparison}. Unlike inducible promoters, its constitutive nature enables consistent gene expression across diverse growth conditions \cite{matsuyama2008series}.
To generate strain HN0101, an mNeonGreen expression cassette with a KanMX6 selection marker was integrated at the pseudogene locus (SPBC1348.11) on chromosome II of the wild-type FY18675 strain (provided by the National BioResource Project, NBRP). Cells were cultured in Edinburgh Minimal Medium (EMM) at 30°C as previously described \cite{moreno199156}. EMM is a synthetic medium commonly used for fission yeast culture, containing glucose as the primary carbon source along with amino acids, vitamins, and minerals. EMM can be adapted to specific experimental needs, such as adjusting nutrient concentrations or enhancing buffering capacity \cite{petersen2016growth}. The medium composition is detailed in Table S??.

\section{Microfluidic Device Fabrication}
The microfluidic device consisted of observation chambers and flow channels. Photomasks were developed on mask blanks (Clean Surface Technology) using a maskless lithography system (μmLA, Heidelberg Instruments). Devices were fabricated from polydimethylsiloxane (PDMS) using molds prepared on silicon wafers (University Wafers) as follows (Figure 3):
Observation channel layer: SU-8 2 (MicroChem) and SU-8 3005 (MicroChem) were mixed at the appropriate ratio, and 1 mL was dispensed onto a silicon wafer and spin-coated at 3,000 rpm for 30 s (Mikasa MS-A150). The wafer was soft-baked at 65°C for 1 min and 95°C for 2 min. The observation channel mask was aligned, and the wafer was exposed to UV light using a mask aligner (Mikasa MA-20) with three exposures of 5.0 s each. Post-exposure baking was performed at 65°C for 1 min and 95°C for 3 min, followed by development in SU-8 developer (MicroChem), rinsing with isopropanol, and drying.
Drain layer: SU-8 3010 (MicroChem) was dispensed onto the wafer with the completed observation channel layer and spin-coated at 1,500 rpm for 30 s. After soft-baking at 65°C for 1 min and 95°C for 8 min, the drain channel mask was aligned to the observation channel alignment marks and exposed to UV light for 30 s. Post-exposure baking was performed at 65°C for 3 min and 95°C for 10 min, followed by development, rinsing, and drying as described above.
PDMS device assembly: SYLGARD 184 (Dow Silicones Corporation) base and curing agent were mixed at a 10:1 ratio, degassed under vacuum for 1 h, and poured onto the silicon wafer mold. After curing at 65°C for at least 12 h, PDMS blocks were cut to size, and inlet/outlet ports were punched using a 0.5-mm biopsy punch (BP-A05F). Blocks were sonicated in ethanol and dried at 65°C.
Cover glass preparation: Cover glasses (Matsunami NEO No.1, 0.13–0.17 mm) were sonicated sequentially in diluted Contaminon LS-II (Wako), ultrapure water, ethanol, and ultrapure water. Cover glasses were then treated with 0.1 M sodium hydroxide, rinsed with ultrapure water, and dried at 140°C.
Bonding: PDMS blocks and cleaned cover glasses were treated with a plasma etcher (FA-1, SAMCO) for 10 s and immediately bonded, taking care to avoid air bubbles and debris.
Epoxy replica fabrication: A PDMS negative mold was first generated from the original silicon wafer master by casting SYLGARD 184 (10:1 ratio, degassed for 1 h) and curing at 65°C for at least 12 h. The PDMS mold was then used to cast epoxy replicas using two-part rigid epoxy (LOCTITE EA E-30CL) on plastic plates, allowing complete curing for at least 24 h. These epoxy replicas served as reusable masters for subsequent PDMS device fabrication.

\begin{figure}[htbp]
\centering
\includegraphics[width=150mm]{fablication.pdf}
\caption{\textnormal{\textbf{マイクロ流体デバイスの作製} SU-8マスターモールドの作製,モールド上へのポリジメチルシロキサン（PDMS）のキャスティング,プラズマ処理によるスライドガラスへの接着過程の模式図を表している.}}
\end{figure}

\section{Time-Lapse Imaging}
Exponential-phase S. pombe cells cultured in EMM (2\% glucose) at 30°C were harvested from 20 mL cultures by centrifugation at 3,700 rpm for 5 min (HITACHI himac CT6E) to generate a 100-fold concentrated cell suspension. The concentrated suspension was loaded into the microfluidic device using a 1-mL syringe (Terumo).
To insert cells into the observation channels, the device was centrifuged at 1,200 rpm for 5 min, rotated 180°, and centrifuged again for 5 min. After confirming cell trapping within the observation channels by microscopy, EMM (2\% glucose) was perfused at 2 mL/h. Cells were allowed to settle until excess cells were completely flushed from the drain channels. Time-lapse imaging was then initiated after registering cell positions.
For media exchanges to EMM (low\% glucose) or EMM (0\% glucose), the entire tubing system, including the connector, was replaced. The appearance of air bubbles in the connector, visualized by live microscopy, was used as the reference point to define the next frame as the time of media exchange.
Media perfusion was controlled by a syringe pump (Harvard ULTRA-P), maintaining a constant flow rate of 2 mL/h throughout the experiments to ensure stable environmental conditions.

\section{タイムラプス計測と画像の取得}
タイムラプス計測には,温度を正確に制御するためのサーモスタットチャンバー（TIZHB,TokaiHit）を備えた電動倒立顕微鏡（Nikon,Ti-E）を使用した.デジタルCMOSカメラ（ORCA C14440 ,浜松ホトニクス）,LED光源（Thorlabs）を組み合わせ,対物レンズはPlan Apo $\lambda$D 40x / 0.95(MRD70470,Nikon)を,GFP蛍光のフィルターキューブにはGFP-B(EX 460-500, DM 505, EM 510-560)を使用した.撮影はMicromanagerソフトウェア（https://micro-manager.org/）で制御し,5分間隔で画像を取得した.明視野画像の露光時間は50ミリ秒,GFP蛍光画像の露光時間は500ミリ秒とした.観察期間は実験条件によって異なり,192時間から240時間であった.長期間のタイムラプス撮影中には,焦点面の安定性を保つためにパーフェクト・フォーカス・システム（PFS）を使用した.すべての観察は30℃で実施した.


\section{画像解析}
明視野（BF）画像のセグメンテーションは,顕微鏡における細胞セグメンテーションに一般的に使用される深層学習ベースのアルゴリズムであるOmnipose\cite{cutler2022omnipose}の半自動ワークフローを用いてセグメンテーションした.Omnipose は,大規模なパラメータチューニングをすることなく,様々なタイプの画像を正確にセグメントできることで知られている.BF画像のセグメンテーションを容易にするために,Omniposeモデルは,パラメータ調整なしで,GFP蛍光画像から得られたマスク画像からなるグランドトゥルースデータを用いて学習された.得られた学習済みモデルをBF画像に適用した(図4). 
\begin{figure}[htbp]
\centering
\includegraphics[width=50mm]{Omnipose.pdf}
\caption{\textnormal{\textbf{Omniposeインターフェース}Omniposeではリアルタイムのフィードバックデータのインタラクティブな解析を可能にする.表示されている生データはBF画像に訓練済みのモデルを用いて,セグメンテーションを行ったマスクを重ね合わせた図}}
\end{figure}

To correct for sample drift during time-lapse imaging, we calculated alignment transformations using the Enhanced Correlation Coefficient (ECC) algorithm \cite\{evangelidis2008parametric\}. Alignment transformations were computed using images from empty channels (no cells present) to register against immobile channel structures. The resulting transformation matrices were stored and subsequently applied to cell-containing channel images using affine transformation. To isolate cellular phase signals from residual channel structures, the empty channel was subtracted from all subsequent frames, yielding differential phase images Δφ(\textit{x,y,t}) representing only cellular refractive index contributions.

\section{Cell Segmentation}
Cell boundaries were detected using Omnipose \cite{cutler2022omnipose}, a deep learning-based segmentation method optimized for bacterial morphology. We trained a custom Omnipose model on approximately 3000 manually annotated S. pombe cells. Training images were first manually annotated using the Omnipose GUI to generate ground truth segmentation masks. Segmentation masks were converted to binary outlines by detecting pixel discontinuities at cell boundaries using morphological operations. Specifically, boundaries were identified where mask values differed from their four-connected neighbors, generating single-pixel-width contours.

\section{Glucose Concentration Measurement}
Glucose concentrations in EMM media were determined using the LabAssay™ Glucose kit (FUJIFILM Wako Pure Chemical Corporation, product code 291-94001) according to the manufacturer's protocol. Absorbance was measured at 505 nm.

